{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0c0fa8-585d-4033-b279-90e55cf2652d",
   "metadata": {},
   "source": [
    "# Cryosphere model Comparison tool (CmCt) Dynamic Thickness Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8788c4-1306-4c5d-a305-43ab8e805dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/dynamic_thickness_calibration\n",
      "/home/jovyan/CmCt/notebooks/DynamicThickness\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import xarray as xr\n",
    "import pyproj\n",
    "import time\n",
    "import netCDF4\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import concurrent.futures\n",
    "\n",
    "import dh_utils\n",
    "import gridding_utils\n",
    "from bilinear_interp import bilinear_interp\n",
    "# TEMPORARY OVERRIDE\n",
    "%cd \"/home/jovyan/dynamic_thickness_calibration\"\n",
    "from read_csv_2007_2015 import read_csv_data   \n",
    "%cd \"/home/jovyan/CmCt/notebooks/DynamicThickness\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8502e670-dcae-4f12-83fa-498094c01c75",
   "metadata": {},
   "source": [
    "## About This Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48855a8e-bf67-49f1-905b-7f037e9ddeed",
   "metadata": {},
   "source": [
    "The CmCt Dynamic Thickness Tool compares the user's uploaded ice sheet model(s) to dynamic thickness data from IMAU, GSFC, and/or GEMB observation data. This observation data is a rectangular grid in UTM zone 24N coordinates but the model is expected as a rectangular grid in ISMIP6 polar-stereographic coordinates (see the Input Data Requirements section). The model data is bilinearly interpolated to observation space and the residual is outputted as a netCDF4 file in observation space. \n",
    "\n",
    "The model currently uses these three datasets made by CREDIT HERE, and available upon request from ACCESS HERE. These datasets include dynamic thickness anomaly data from balance years 1995 to 2021: `Dynamic_h_Greenland_GEMB_1994_2021.nc`, `Dynamic_h_Greenland_GSFC_1994_2021.nc`, and `Dynamic_h_Greenland_IMAU_1994_2020.nc`. See OBSERVATION DATA DOCUMENTATION HERE for more information about these datasets.\n",
    "\n",
    "### Multiple Comparisons\n",
    "This tool uses parallel processing to allow the user to efficiently compare multiple model files with multiple observation files. A comparison can occur between any observation file (of the three listed above) and any model file listed in the `model_fns` input in any balance year for which both have data, or even for a range of years. The user may request any amount of comparisons be done. See the \"Desired Comparisons\" subsection of the \"Input Data Requirements\" section for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db370cb2-bdfb-48f6-8282-aea2bc2ca4e5",
   "metadata": {},
   "source": [
    "## Input Data Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c5169-6df2-4ee9-a82f-a892e0024659",
   "metadata": {},
   "source": [
    "### Input netCDF file requirements\n",
    "The user may include multiple netCDF4 model files, but they must contain these four variables: x, y, time, and dh. \n",
    "\n",
    "#### Coordinate System (x and y variables)\n",
    "Coordinates are defined on a rectangular X-Y grid in the ISMIP6 standard projected polar-stereographic space. The ISMIP6 standard projection is defined [here](https://theghub.org/groups/ismip6/wiki/ISMIP6-Projections-Greenland). This means that in the model netCDF4 file, there must be variables x and y such that x has dimensions (x,) and length A and y has dimensions (y,) and length B. If multiple netCDF4 files are entered as inputs, their x and y variables are assumed to be the same, and behavior of this tool is undefined in the case that they are not. \n",
    "\n",
    "#### Time\n",
    "Must be an array of integers, floats, or strings representing the number of years since AD 0. \"1996\", 1996.0, and 1996 are all acceptable entries, but no month, day, time-of-day, or timezone information should be provided. The entries of `time` must be in increasing order and consecutive. If multiple netCDF4 files are entered as inputs, their time variables may be different (i.e. one model file may include data from 1996 to 2006, another may include data from 2000 to 2010) as long as they follow these guidelines.\n",
    "\n",
    "#### Dh variable\n",
    "The CmCt Grace Mascon tool expects the uploaded model to contain dynamic thickness data (the `dh` variable) for the comparison (should be in units of meters). dh must have dimensions (time, y, x) such that dh\\[i,j,k] is the change in dynamic thickness anomaly in meters from Sep 1st, time\\[i] to Aug 31st, time\\[i] + 1 at the position described by (x\\[k], y\\[j]) in ISMIP6 polar-stereographic space.\n",
    "\n",
    "\n",
    "### Desired Comparisons\n",
    "The filenames of all model files the user wishes to include should be listed in the variable `model_fns` as a list of strings. The input `desired_comparisons` is a list of 4-tuples of the form `(obs_src, idx_mod, start_year, end_year)`. `obs_src` should be either \"IMAU\", \"GEMB\" or \"GSFC\" to indicate the observation dataset. `idx_mod` is an index of `model_fns` to indicate the model dataset. \n",
    "\n",
    "`start_year` and `end_year` should be ints representing the start and end year of the comparison. For example, if `start_year` = 1996 and `end_year` = 1997, then the observation change in dynamic thickness anomaly from Sep 1st, 1996 to Aug 31st 1997 will be compared with the modelled change in dynamic thickness anomaly from Sep 1st, 1996 to Aug 31st 1997. Likewise, if `start_year` = 2007 and `end_year` = 2015, then the observation change in dynamic thickness anomaly from Sep 1st, 2007 to Aug 31st 2015 will be compared with the modelled change in dynamic thickness anomaly from Sep 1st, 2007 to Aug 31st 2015. Note that the start and end years cannot occur before the start of observation data collection (1995) or after the end of observation data collection (2021 for GSFC and GEMB, 2020 for IMAU).\n",
    "\n",
    "\n",
    "### Regridding\n",
    "The user has the option to regrid the model and observation data to a grid in polar stereographic with their choice of resolution and extent. This is controlled by the `regrid` input variable. If `regrid` is False, then the model data will be interpolated to observation coordinates and subtracted, giving a residual which is in observation space (aka a grid in UTM zone 24N). If `regrid` is True, then the user will have to supply other input variables denoting the extent and resolution of the desired grid in polar-stereographic coordinates. Both model and observation data will be converted to this new grid before being subtracted to give a residual. The method of conversion is the same for model and observation data: all datapoints spatially contained within a certain grid cell will be averaged to give the value for that grid cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ab95b-9f0f-421d-b4ec-a3b8853fe771",
   "metadata": {},
   "source": [
    "## Outputs and Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac5579d-8f41-4785-b379-034366b771e6",
   "metadata": {},
   "source": [
    "The CmCt offers multiple options for output saving and plotting. \n",
    "\n",
    "### Saving\n",
    "If the input `save_nc` is False, the CmCt will not save any netCDF files. Otherwise, in the case that only one comparison is desired, the CmCt will create a netCDF file (with the filename being the first entry of the `output_fns` list) which has the following variables: x, y, dh_res, and spatial_ref. dh_res will store the residual of the comparison as a grid in UTM zone 24N and will have dimensions (y, x).\n",
    "\n",
    "In the case that multiple comparisons are desired (and `save_nc` is True), the user has two options controlled by the input variable `single_file_nc`. If `single_file_nc` is False, then each residual will be saved in a netCDF file of the form described above. The comparison described by desired_comparisons\\[i] will be saved with the filename output_fn\\[i]. \n",
    "\n",
    "If `single_file_nc` is True, then all residuals will be stacked and saved in a single netCDF file to the filename output_fns\\[0]. This file will have the following variables: x, y, spatial_ref, obs_src, model_id, start_year, end_year, all_dh_res. There is also a \"comparison\" dimension, which has the same length as desired_comparisons. all_dh_res has the form (comparison, y, x), where all_dh_res\\[i,:,:] is the residual for desired_comparison\\[i]. obs_src, model_id, start_year, and end_year each have form (comparisons,) and store the observation source (either \"IMAU\", \"GSFC\", or \"GEMB\"), model id (given by the input `model_ids`), start_year, and end_year for each comparison respectively. If the `model_fn_ids` input is None, then the model_id for each model will be the filename given in `model_fn` (this is not recommended).\n",
    "\n",
    "### Plotting\n",
    "The `plot` variable is an array of booleans with the same length as `desired_comparisons`, and if `plot`\\[i] is True, the observation data, model data, and residual for `desired_comparisons`\\[i] will be plotted. The `save_plot` variable is an array of booleans with the same length as `desired_comparisons`, and if `plot`\\[i] and `save_plot`\\[i] are True, the plot for `desired_comparisons`\\[i] will be saved to `plot_fn`\\[i]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d8f415-ed82-4b0c-865e-09ecb6c7294e",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d626ff-7423-4a58-99e1-6453cafa2b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model filenames (see \"Desired Comparisons\" subsection above for more info)\n",
<<<<<<< Updated upstream
    "n = 128\n",
=======
    "n = 12\n",
>>>>>>> Stashed changes
    "model_fns = [\"/home/jovyan/shared-public/CmCt/models/ensemble/gris.proj.2007-2015.A1\" \n",
    "             + (str(i)).zfill(3) + \".dhdynAnom6079.nc\" for i in range(n)]\n",
    "\n",
    "# TEMPORARY OVERRIDE\n",
    "desired = \"IMAU\"\n",
    "\n",
    "# Desired comparisons (see \"Desired Comparisons\" subsection above for more info)\n",
    "desired_comparisons = [(\"IMAU\", i, 2007, 2015) for i in range(n)]\n",
    "\n",
    "# Initialize optional preference variables to None\n",
    "single_file_nc, save_plot, plot_fn, output_fns, model_fn_ids, extent, grid_size = None, None, None, None, None, None, None\n",
    "\n",
    "regrid = True\n",
    "if regrid:\n",
    "    extent = np.array([-720500.0, 960500.0, -3450500.0, -569500.0])  # Left, right, top, bottom in polar stereographic\n",
    "    grid_size = 5000.   # Units of meters in polar stereographic\n",
    "\n",
    "# Plotting and Saving Preferences\n",
    "save_nc = True\n",
    "if save_nc:   single_file_nc = True\n",
    "plot = np.ones((n,)).astype('bool')\n",
    "if np.sum(plot):      save_plot = np.zeros((n,)).astype('bool')\n",
    "\n",
    "\n",
    "# Plotting and Saving Needed Information\n",
    "if save_nc:\n",
    "    output_fns = [\"output_files/res_\"+desired+\"_A1\" + (str(i)).zfill(3) + \".nc\" for i in range(n)]\n",
    "\n",
    "    if single_file_nc:\n",
    "        output_fns = [\"output_files/5km_grid/residuals_\"+desired+\"_5km_grid_2007_2015.nc\"]\n",
    "        model_fn_ids = [\"A1\" + (str(i)).zfill(3) for i in range(n)]\n",
    "\n",
    "    # TEMPORARY OVERRIDE\n",
    "    sigma_save_fn = \"output_files/5km_grid/sigma_\"+desired+\"_5km_grid_0715.nc\"\n",
    "\n",
    "if np.sum(plot):\n",
    "    if np.sum(save_plot):\n",
    "        plot_fn = [\"output_files/plot_\"+desired+\"_2007_2015/\" + model_fn_ids[i] + \".png\" for i in range(n)]\n",
    "\n",
    "\n",
    "# Check the validity of inputs; error is a boolean\n",
    "global error\n",
    "error = dh_utils.check_input_validity(save_nc, output_fns, single_file_nc, len(desired_comparisons), \n",
    "                                      model_fn_ids, len(model_fns), plot, save_plot, plot_fn, \n",
    "                                     regrid, extent, grid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5342c-521c-4aa6-bb65-23d0e2faab73",
   "metadata": {},
   "source": [
    "## Read in Observation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b02ff9-bac2-4699-9258-f6648788275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_obs_file(desired_comparisons):\n",
    "    global x_UTM\n",
    "    global y_UTM\n",
    "    global crs_wkt\n",
    "\n",
    "    obs_paths = {\"IMAU\": \"observation_data/Dynamic_h_Greenland_IMAU_1994_2020.nc\", \n",
    "                 \"GEMB\": \"observation_data/Dynamic_h_Greenland_GEMB_1994_2021.nc\",\n",
    "                 \"GSFC\": \"observation_data/Dynamic_h_Greenland_GSFC_1994_2021.nc\"}\n",
    "\n",
    "    # Outputs. For a more complete description, see the runProcessing function\n",
    "    all_dh_obs = []      # list of 2D arrays\n",
    "    comp_2_obs_idx = np.empty((len(desired_comparisons),), dtype = \"int\")\n",
    "\n",
    "    # Interpret the list of tuples into a format that prevents duplicating data\n",
    "    comp_info = dh_utils.manage_comparisons(desired_comparisons, True)\n",
    "\n",
    "    set_common_vars = False\n",
    "    for src in comp_info:\n",
    "        # Read in file info\n",
    "        fn = obs_paths[src]\n",
    "        with h5py.File(fn, mode='r') as f:\n",
    "            if not set_common_vars:        # Ensures this is only done once, not three times\n",
    "                x_UTM = f['x'][:]\n",
    "                y_UTM = f['y'][:]\n",
    "                spatial_ref = f['spatial_ref']\n",
    "                crs_wkt = spatial_ref.attrs['crs_wkt'].decode('UTF-8')   # Contains coordinate system data\n",
    "                set_common_vars = True\n",
    "\n",
    "            time_obs = (f['time'][:]).astype(\"int\")\n",
    "            dh = f['dh'][:]    # Has shape (len(time_obs), len(y_UTM), len(x_UTM))\n",
    "\n",
    "\n",
    "        # Select only years of dh data needed for some comparison; construct outputs\n",
    "        for start_year, end_year in comp_info[src]:\n",
    "            start_bal_year, end_bal_year = start_year, end_year - 1\n",
    "\n",
    "            # Check that both years are within the bounds of observation\n",
    "            if not (dh_utils.time_within_bounds(start_bal_year, time_obs, \"Desired start year\", \"observation data\")\n",
    "                        & dh_utils.time_within_bounds(end_bal_year, time_obs, \"Desired end year\", \"observation data\")):\n",
    "                return None, None\n",
    "\n",
    "            # Compute the total change over this timescale\n",
    "            time_idx_start = np.argwhere(time_obs == start_bal_year)[0,0]\n",
    "            time_idx_end = np.argwhere(time_obs == end_bal_year)[0,0]\n",
    "            dh_obs = np.sum(dh[time_idx_start:(time_idx_end + 1), :, :], axis = 0)\n",
    "\n",
    "            # Append to all_dh_obs and update comp_2_obs_idx\n",
    "            all_dh_obs.append(dh_obs)\n",
    "            obs_idx = len(all_dh_obs) - 1\n",
    "            for i in (comp_info[src])[(start_year, end_year)]:\n",
    "                comp_2_obs_idx[i] = obs_idx\n",
    "        dh = None   # De-allocate memory\n",
    "        \n",
    "    return all_dh_obs, comp_2_obs_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c3ac4-ee89-405e-9a18-62760b58f599",
   "metadata": {},
   "source": [
    "## Read in Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce23e37-a282-4f3d-ba64-4e1f107bacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_file(model_fns, desired_comparisons):\n",
    "    global x_mod\n",
    "    global y_mod\n",
    "\n",
    "    # Outputs. For a more complete description, see the runProcessing function\n",
    "    all_dh_mod = []\n",
    "    comp_2_mod_idx = np.empty((len(desired_comparisons),), dtype = \"int\")\n",
    "\n",
    "    # Interpret the list of tuples into a format that prevents duplicating data\n",
    "    comp_info = dh_utils.manage_comparisons(desired_comparisons, False)\n",
    "    \n",
    "    set_common_vars = False\n",
    "    for idx_mod in comp_info:     # Iterate over model files\n",
    "        # Read file data\n",
    "        fn = model_fns[idx_mod]\n",
    "        with h5py.File(fn , mode='r') as f:\n",
    "            if not set_common_vars:\n",
    "                # See \"Input Data Requirements\" section for more details on the format of these variables\n",
    "                x_mod = f['x'][:]\n",
    "                y_mod = f['y'][:]\n",
    "                set_common_vars = True\n",
    "\n",
    "            time_mod = (f['t'][:]).astype(\"int\")\n",
    "            dh = f['dh_dynAnom'][:]   #dh = f['dh_dynAnom'][:]\n",
    "\n",
    "\n",
    "        # Select only years of dh data needed for some comparison; construct outputs\n",
    "        for start_year, end_year in comp_info[idx_mod]:\n",
    "            start_bal_year, end_bal_year = start_year, end_year - 1\n",
    "\n",
    "            # Check that both years are within the bounds of observation\n",
    "            if not (dh_utils.time_within_bounds(start_bal_year, time_mod, \"Desired start year\", \"model data\")\n",
    "                        & dh_utils.time_within_bounds(end_bal_year, time_mod, \"Desired end year\", \"model data\")):\n",
    "                return None, None\n",
    "\n",
    "            # Compute the total change over this timescale\n",
    "            time_idx_start = np.argwhere(time_mod == start_bal_year)[0,0]\n",
    "            time_idx_end = np.argwhere(time_mod == end_bal_year)[0,0]\n",
    "            dh_mod = np.sum(dh[time_idx_start:(time_idx_end + 1), :, :], axis = 0)\n",
    "\n",
    "            # Append to all_dh_mod and update comp_2_mod_idx\n",
    "            all_dh_mod.append(dh_mod)\n",
    "            mod_idx = len(all_dh_mod) - 1\n",
    "            for i in (comp_info[idx_mod])[(start_year, end_year)]:\n",
    "                comp_2_mod_idx[i] = mod_idx\n",
    "                \n",
    "        dh = None   # De-allocate memory\n",
    "            \n",
    "    return all_dh_mod, comp_2_mod_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42aba1-dfda-4bf7-a1a4-142baee9e90b",
   "metadata": {},
   "source": [
    "## Transform Observation Coordinates from UTM-24N to ISMIP6 polar-stereographic coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbcb88af-e681-44de-90bb-7aa284b3ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_UTM_grid_to_list_of_polar_stereo_points(crs_wkt, x_UTM, y_UTM):\n",
    "    # See \"About This Tool\" section for observation coordinate system information\n",
    "    \n",
    "    # Make a transformer from observation coordinates to model coordinates\n",
    "    crs_utm = pyproj.crs.CRS.from_wkt(crs_wkt)    # Coordinate system of observation data\n",
    "    crs_ps = gridding_utils.crs_ps()\n",
    "    utm_to_ps = pyproj.Transformer.from_crs(crs_from = crs_utm, crs_to = crs_ps)\n",
    "\n",
    "    # Format observation coordinate data into two 1D arrays of the same length\n",
    "    #x_UTM_points, y_UTM_points = gridding_utils.flatten_to_list_of_points(x_UTM, y_UTM)\n",
    "\n",
    "    # TEMPORARY OVERRIDE\n",
    "    x_UTM_points, y_UTM_points = X_32624, Y_32624\n",
    "    \n",
    "    # Transform observation coordinate points to points in polar-stereographic space\n",
    "    x_obs, y_obs = utm_to_ps.transform(x_UTM_points, y_UTM_points)\n",
    "    return x_obs, y_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8380b6-e809-4d59-ad62-8ed44f94ff8d",
   "metadata": {},
   "source": [
    "## Interpolate Model to Observation Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12130870-606f-43ac-9c5f-80e3c9c2db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_all_models_to_observation_space(x_obs, y_obs, dh_obs, all_dh_mod):\n",
    "    \"\"\"\n",
    "    Wrapper function for interp_one_model_to_obs_space which parallelizes the interpolation operation of all models\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set inputs to interp_one_model_to_obs_space that will not vary between calls\n",
    "    global I_\n",
    "    global x_query, y_query     # Interpolation query points (does not include points which are NaN in observation data)\n",
    "    global newshape             # Shape that the model will be interpolated to\n",
    "    \n",
    "    I_ = (~np.isnan(dh_obs)).transpose().flatten()   # I_[i] is False if x_obs[i], y_obs[i] correspond to a point where dh_obs is NaN, True otherwise\n",
    "    x_query, y_query = x_obs[I_], y_obs[I_]\n",
    "    newshape = dh_obs.shape\n",
    "\n",
    "    # Parallelize the interpolation and reshaping step in order to speed up\n",
    "    if len(all_dh_mod) == 1:\n",
    "        return [interp_one_model_to_obs_space(all_dh_mod[0])]\n",
    "    else:\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            generator = executor.map(interp_one_model_to_obs_space, all_dh_mod)\n",
    "            \n",
    "        all_dh_mod_interped = []\n",
    "        for dh_mod_interped in generator:\n",
    "            all_dh_mod_interped.append(dh_mod_interped)\n",
    "        return all_dh_mod_interped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201893d4-6347-4133-b2c3-5edc873b7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_one_model_to_obs_space(dh_mod):\n",
    "    \"\"\"\n",
    "    Interpolates a model dh 2D array to observation space and reshape to newshape\n",
    "    \"\"\"\n",
    "    \n",
    "    # Bilinearly interpolate model to observation space\n",
    "    model_dh_interped_flat = bilinear_interp(x_mod, y_mod, dh_mod, x_query, y_query)\n",
    "\n",
    "    # Reshape model array to the same shape as the observation array\n",
    "    dh_mod_interped = np.empty_like(I_, dtype = np.float64)\n",
    "    dh_mod_interped[~I_] = np.nan     # Fill with NaN at indices where dh_obs is NaN\n",
    "    dh_mod_interped[I_] = model_dh_interped_flat\n",
    "    dh_mod_interped = np.reshape(dh_mod_interped, newshape, order = \"F\")\n",
    "    return dh_mod_interped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06a830-13cd-457f-9c76-e9b38833f5dc",
   "metadata": {},
   "source": [
    "## Subtract Model and Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe33180-1a35-468d-ab84-9eaada790a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_residuals(all_dh_obs, comp_2_obs_idx, all_dh_mod_interped, comp_2_mod_idx):\n",
    "    \"\"\"\n",
    "    For each comparison in desired_comparisons, computes the residual and outputs all residuals\n",
    "    as a list such that all_dh_res[i] corresponds to desired_comparison[i]\n",
    "\n",
    "    See runProcessing function for details on the inputs to this function\n",
    "    \"\"\"\n",
    "    all_dh_res = []\n",
    "    for i in range(len(comp_2_obs_idx)):\n",
    "        obs_idx = comp_2_obs_idx[i]\n",
    "        mod_idx = comp_2_mod_idx[i]\n",
    "        all_dh_res.append(all_dh_mod_interped[mod_idx] - all_dh_obs[obs_idx])  # residual = model - observation\n",
    "    return all_dh_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e16ab-a3ec-40a1-89f4-06820109886c",
   "metadata": {},
   "source": [
    "## Plot Observation, Model, and Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac3a4f9-aae5-4b30-bd1c-e4b886aaafe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_obs_mod_res(extent, dh_obs, dh_mod_interped, dh_res, year, save_plot, plot_fn):\n",
    "    mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "    mpl.rcParams['figure.dpi'] = 100\n",
    "    fig = plt.figure(figsize=(24,14))\n",
    "\n",
    "    \"\"\"\n",
    "    mins = [np.nanmin(dh_obs), np.nanmin(dh_mod_interped), np.nanmin(dh_res)]\n",
    "    min = np.nanmin(mins)\n",
    "    maxs = [np.nanmax(dh_obs), np.nanmax(dh_mod_interped), np.nanmax(dh_res)]\n",
    "    max = np.nanmax(maxs)\n",
    "    \"\"\"\n",
    "    # TEMPORARY!!!! HARD-CODED IN\n",
    "    min = -25\n",
    "    max = 25\n",
    "\n",
    "    # Observation\n",
    "    ax1 = plt.subplot(131)\n",
    "    im1 = ax1.imshow(dh_obs, aspect = \"equal\", origin = \"lower\", extent = extent, vmin = min, vmax = max, cmap = \"RdYlBu\")\n",
    "    ax1.set_xbound(lower = extent[0], upper = extent[1])\n",
    "    ax1.set_ybound(lower = extent[2], upper = extent[3])\n",
    "    ax1.set_xlim(left = extent[0], right = extent[1])\n",
    "    ax1.set_ylim(bottom = extent[2], top = extent[3])\n",
    "    ax1.set_title(f\"Observed\", fontsize = 18)\n",
    "    \n",
    "    \n",
    "    # Model\n",
    "    ax2 = plt.subplot(132)\n",
    "    im2 = ax2.imshow(dh_mod_interped, aspect = \"equal\", origin = \"lower\", extent = extent, vmin = min, vmax = max, cmap = \"RdYlBu\")\n",
    "    ax2.set_xbound(lower = extent[0], upper = extent[1])\n",
    "    ax2.set_ybound(lower = extent[2], upper = extent[3])\n",
    "    ax2.set_xlim(left = extent[0], right = extent[1])\n",
    "    ax2.set_ylim(bottom = extent[2], top = extent[3])\n",
    "    ax2.set_title(f\"Modelled (interpolated)\", fontsize = 18)\n",
    "    \n",
    "\n",
    "    # Residual\n",
    "    ax3 = plt.subplot(133)\n",
    "    im3 = ax3.imshow(dh_res, aspect = \"equal\", origin = \"lower\", extent = extent, vmin = min, vmax = max, cmap = \"RdYlBu\")\n",
    "    ax3.set_xbound(lower = extent[0], upper = extent[1])\n",
    "    ax3.set_ybound(lower = extent[2], upper = extent[3])\n",
    "    ax3.set_xlim(left = extent[0], right = extent[1])\n",
    "    ax3.set_ylim(bottom = extent[2], top = extent[3])\n",
    "    ax3.set_title(f\"Residual (Model - Observation)\", fontsize = 18)\n",
    "    \n",
    "    # Add shared colorbar\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    cbar_ax = fig.add_axes([0.875, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(im1, cax=cbar_ax)\n",
    "    fig.colorbar(im2, cax=cbar_ax)\n",
    "    fig.colorbar(im3, cax=cbar_ax)\n",
    "    cbar_ax.set_ylabel(\"meters\", fontsize = 16)\n",
    "    fig.suptitle(\"Dynamic Thickness Anomaly Change \" + str(year), fontsize = 24)\n",
    "\n",
    "    if save_plot:\n",
    "        plt.savefig(plot_fn)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33032177-3995-456f-895b-f8625e66e69c",
   "metadata": {},
   "source": [
    "## Compute Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d581b2db-e0a1-46ee-a164-2495188efef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runProcessing():\n",
    "    \"\"\"\n",
    "    Before reading, see the \"Desired Comparisons\" subsection of the \"Input Data Requirements\" section.\n",
    "\n",
    "    Here is a summary of what the tool does at a basic level. First it reads in the model and \n",
    "    observation data for the appropriate years. It then transforms the spatial coordinates of the \n",
    "    observation data from a grid in UTM-24N to a set of non-gridded points in polar-stereographic\n",
    "    coordinates. Then, using the fact that the model data is a grid in polar-stereographic, the tool\n",
    "    uses bilinear interpolation to estimate the value of the model data at the locations of the \n",
    "    observation data. This and the observation data are then subtracted, giving the residual. Below \n",
    "    is a more detailed account of the pipeline, which defines the behavior of important variables.\n",
    "\n",
    "    Pipeline:\n",
    "    1) Read in observation data as a list of 2D arrays called all_dh_obs. Each entry of all_dh_obs has\n",
    "       the same shape, let this be (ny, nx). Each entry of all_dh_obs is for a different year/year-range\n",
    "       or source necessary in some comparison in desired_comparisons. The variable comp_2_obs_idx records \n",
    "       which comparisons need which entry of all_dh_obs: comp_2_obs_idx[i] is the index of all_dh_obs which \n",
    "       holds the observation data needed for desired_comparison[i]. The spatial information for all \n",
    "       observation data arrays is stored in x_UTM and y_UTM, and x_UTM has length nx and y_UTM has \n",
    "       length ny.\n",
    "    2) Read in model data as a list of 2D arrays called all_dh_mod. Each entry of all_dh_mod is assumed \n",
    "       to have the same shape. Each entry of all_dh_mod is for a different year/year range or model \n",
    "       necessary in some comparison in desired_comparisons. The variable comp_2_mod_idx records which \n",
    "       comparisons need which entry of all_dh_mod: comp_2_mod_idx[i] is the index of all_dh_mod which holds \n",
    "       the model data needed for desired_comparison[i]. The spatial information for all model data arrays \n",
    "       is stored in x_mod and y_mod. See the \"Coordinate System\" subsection of the \"Input Data Requirements\" \n",
    "       section for more information.\n",
    "    3) Reshape coordinate information encoded in x_UTM and y_UTM to a set of points described by two 1D \n",
    "       arrays (both with length nx * ny), which are then converted into polar stereographic coordinates. \n",
    "       These arrays are x_obs and y_obs.\n",
    "    4) If regrid = True, regrid all entries of all_dh_obs and all_dh_mod to the desired grid, then subtract.\n",
    "       Otherwise, for each entry of all_dh_mod, bilinearly interpolate from the model's grid in polar stereographic, \n",
    "       using x_obs and y_obs as the query points. This will return an estimated value of the modelled \n",
    "       value at each of the points for which the observation value is known. In other words, the model has \n",
    "       been brought to observation space. Note that this step is done in parallel.\n",
    "    5) For each desired comparison, compute the residual (model - observation) in observation space\n",
    "    6) (Optional) Write all residuals to netCDF4 files\n",
    "    7) (Optional) For a single comparison, plot the observation, model, and residual and optionally save \n",
    "        the plot\n",
    "    \"\"\"\n",
    "    \n",
    "    if error:\n",
    "        return None\n",
    "    \n",
    "    update_progress(0.0, \"Starting...              \", 0.0)\n",
    "    t = time.time()\n",
    "    all_dh_obs, comp_2_obs_idx = read_obs_file(desired_comparisons)     # Sets global variables x_UTM, y_UTM, crs_wkt\n",
    "    if all_dh_obs is None:\n",
    "        return None\n",
    "    update_progress(0.2, \"Read Observation Data    \", time.time() - t)\n",
    "\n",
    "    # TEMPORARY OVERRIDE\n",
    "    global X_32624\n",
    "    global Y_32624\n",
    "    X_32624, Y_32624, dh_SRC_obs, dh_SRC_err = read_csv_data(desired)\n",
    "    comp_2_obs_idx = np.zeros(len(desired_comparisons), dtype = \"int\")\n",
    "\n",
    "    \n",
    "    t = time.time()\n",
    "    all_dh_mod, comp_2_mod_idx = read_model_file(model_fns, desired_comparisons)     # Sets global variables x_mod, y_mod\n",
    "    if all_dh_mod is None:\n",
    "        return None\n",
    "    update_progress(0.4, \"Read Model Data          \", time.time() - t)\n",
    "\n",
    "    # TEMPORARY OVERRIDE WITHIN transform_UTM_grid_to_list_of_polar_stereo_points\n",
    "    t = time.time()\n",
    "    x_obs, y_obs,  = transform_UTM_grid_to_list_of_polar_stereo_points(crs_wkt, x_UTM, y_UTM)\n",
    "    update_progress(0.5, \"Transformed Coordinates  \", time.time() - t)\n",
    "\n",
    "    t = time.time()\n",
    "    if regrid:\n",
    "        # Construct grid\n",
    "        x_centers, y_centers = gridding_utils.grid_centers_from_extent_and_res(extent, grid_size)\n",
    "\n",
    "        # TEMPORARY OVERRIDE\n",
    "        # Regrid observation and model\n",
    "        #all_dh_obs = gridding_utils.regrid_data(x_centers, y_centers, x_obs, y_obs, [dh_obs.transpose().flatten() for dh_obs in all_dh_obs])\n",
    "        arr = gridding_utils.regrid_data(x_centers, y_centers, x_obs, y_obs, [dh_SRC_obs, dh_SRC_err])\n",
    "        all_dh_obs = [arr[0]]\n",
    "        sigma_grid = arr[1]\n",
    "        \n",
    "        x_mod_flat, y_mod_flat = gridding_utils.flatten_to_list_of_points(x_mod, y_mod)\n",
    "        all_dh_mod_interped = gridding_utils.regrid_data(x_centers, y_centers, x_mod_flat, y_mod_flat, [dh_mod.transpose().flatten() for dh_mod in all_dh_mod])\n",
    "    else:\n",
    "        all_dh_mod_interped = interpolate_all_models_to_observation_space(x_obs, y_obs, all_dh_obs[0], all_dh_mod)\n",
    "    all_dh_mod = None    # Deallocate memory\n",
    "    update_progress(0.7, \"Interpolated Model       \", time.time() - t)\n",
    "    \n",
    "\n",
    "    t = time.time()\n",
    "    all_dh_res = compute_residuals(all_dh_obs, comp_2_obs_idx, all_dh_mod_interped, comp_2_mod_idx)\n",
    "    update_progress(0.8, \"Computed Residuals       \", time.time() - t)\n",
    "\n",
    "    \n",
    "    if save_nc:\n",
    "        t = time.time()\n",
    "        if regrid:\n",
    "            dh_utils.save_residuals_to_netcdf(output_fns, all_dh_res, x_centers, y_centers, desired_comparisons, \n",
    "                                              gridding_utils.crs_ps().to_wkt(), single_file_nc, model_fn_ids)\n",
    "        else:\n",
    "            dh_utils.save_residuals_to_netcdf(output_fns, all_dh_res, x_UTM, y_UTM, desired_comparisons, crs_wkt,\n",
    "                                          single_file_nc, model_fn_ids)\n",
    "\n",
    "        # TEMPORARY OVERRIDE\n",
    "        ds = xr.Dataset(data_vars={\"dh_sigma\":((\"y\", \"x\"), sigma_grid)}, coords={\"y\":y_centers, \"x\":x_centers})\n",
    "        ds.to_netcdf(sigma_save_fn)\n",
    "        update_progress(0.9, \"Saved residuals to NetCDF\", time.time() - t)\n",
    "    \n",
    "    if np.sum(plot) > 0:\n",
    "        print(\"Plotting....\")\n",
    "        t = time.time()\n",
    "        for i, b in enumerate(plot):\n",
    "            if b & regrid: \n",
    "                plot_obs_mod_res((x_centers[0], x_centers[-1], y_centers[0], y_centers[-1]), all_dh_obs[comp_2_obs_idx[i]], \n",
    "                         all_dh_mod_interped[comp_2_mod_idx[i]], all_dh_res[i], (desired_comparisons[i])[2], \n",
    "                         save_plot[i], plot_fn[i] if save_plot[i] else None)\n",
    "            elif b & (not regrid): \n",
    "                plot_obs_mod_res((x_UTM[0], x_UTM[-1], y_UTM[0], y_UTM[-1]), all_dh_obs[comp_2_obs_idx[i]], \n",
    "                         all_dh_mod_interped[comp_2_mod_idx[i]], all_dh_res[i], (desired_comparisons[i])[2], \n",
    "                         save_plot[i], plot_fn[i] if save_plot[i] else None)\n",
    "        update_progress(1.0, \"Plotted Results          \", time.time() - t)\n",
    "    \n",
    "    print(\"Success\")\n",
    "    return \"Success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873a6429-ba92-4806-9b53-c77283efca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update processing progress bar\n",
    "def update_progress(progress, title, time_elapsed_print):\n",
    "    bar_length = 20\n",
    "    block = int(20.0*progress)\n",
    "    text = title+\" [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100) + f\" ({time_elapsed_print} seconds)\"\n",
    "    print(text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c9d0d89-6964-46da-8316-816e1f99b2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...               [--------------------] 0.0% (0.0 seconds)\n",
      "Read Observation Data     [####----------------] 20.0% (2.3451013565063477 seconds)\n",
      "Read Model Data           [########------------] 40.0% (68.42394351959229 seconds)\n",
      "Transformed Coordinates   [##########----------] 50.0% (0.023925304412841797 seconds)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t_tot \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrunProcessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal time: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_tot) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 83\u001b[0m, in \u001b[0;36mrunProcessing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     sigma_grid \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     82\u001b[0m     x_mod_flat, y_mod_flat \u001b[38;5;241m=\u001b[39m gridding_utils\u001b[38;5;241m.\u001b[39mflatten_to_list_of_points(x_mod, y_mod)\n\u001b[0;32m---> 83\u001b[0m     all_dh_mod_interped \u001b[38;5;241m=\u001b[39m \u001b[43mgridding_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregrid_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mod_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mod_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdh_mod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdh_mod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_dh_mod\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     all_dh_mod_interped \u001b[38;5;241m=\u001b[39m interpolate_all_models_to_observation_space(x_obs, y_obs, all_dh_obs[\u001b[38;5;241m0\u001b[39m], all_dh_mod)\n",
      "File \u001b[0;32m~/CmCt/notebooks/DynamicThickness/gridding_utils.py:88\u001b[0m, in \u001b[0;36mregrid_data\u001b[0;34m(x_centers, y_centers, x, y, data)\u001b[0m\n\u001b[1;32m     86\u001b[0m             K_ \u001b[38;5;241m=\u001b[39m (y[left:right] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m y_c \u001b[38;5;241m-\u001b[39m y_span\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m (y[left:right] \u001b[38;5;241m<\u001b[39m y_c \u001b[38;5;241m+\u001b[39m y_span\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m---> 88\u001b[0m                 (arrs[w])[j, i] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mw\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m:\u001b[49m\u001b[43mright\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mK_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrs\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:1044\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(out\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf a is inexact, then out must be inexact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1044\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m             \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m tot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(arr, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[1;32m   1047\u001b[0m              where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[1;32m   1048\u001b[0m avg \u001b[38;5;241m=\u001b[39m _divide_by_count(tot, cnt, out\u001b[38;5;241m=\u001b[39mout)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2298\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2295\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t_tot = time.time()\n",
    "runProcessing()\n",
    "print(\"Total time: \" + str(time.time() - t_tot) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a7865-026e-47bb-87bb-b07c1f66b76c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

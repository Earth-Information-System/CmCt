{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c4821-0e1a-4c0e-9b7e-0131722e95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60686ee-f37c-499f-9fb1-7e1fdb742eae",
   "metadata": {},
   "source": [
    "## Step 1: Get list of ICESat GLAH files\n",
    "\n",
    "We use earthaccess, which uses NASA CMR, to query and get a list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9efe0fe-7762-473a-9302-bfac1e792e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are already authenticated with NASA EDL\n",
      "Granules found: 637\n"
     ]
    }
   ],
   "source": [
    "import earthaccess\n",
    "\n",
    "auth = earthaccess.login()\n",
    "\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    short_name='GLAH12',\n",
    "    cloud_hosted=True\n",
    ")\n",
    "  \n",
    "\n",
    "# if the data set is cloud hosted there will be S3 links available. The access parameter accepts \"direct\" or \"external\", direct access is only possible if you are in the us-west-2 region in the cloud.\n",
    "data_links = [granule.data_links(access=\"direct\") for granule in results]\n",
    "\n",
    "# # or if the data is an on-prem dataset\n",
    "# data_links = [granule.data_links(access=\"external\") for granule in results]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bc5040-0a80-4320-9bb8-38426f85591c",
   "metadata": {},
   "source": [
    "# Step 2: Get list of CmCt (Greenland) files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caba7fa-142c-45a7-b0ce-7ece9da77039",
   "metadata": {},
   "source": [
    "## Loop through CmCt dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241ed9b9-836f-4167-96a8-7306c4d3f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NSIDC credentials\n",
    "s3_cred_endpoint = {\n",
    "    'podaac':'https://archive.podaac.earthdata.nasa.gov/s3credentials',\n",
    "    'gesdisc': 'https://data.gesdisc.earthdata.nasa.gov/s3credentials',\n",
    "    'lpdaac':'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials',\n",
    "    'ornldaac': 'https://data.ornldaac.earthdata.nasa.gov/s3credentials',\n",
    "    'ghrcdaac': 'https://data.ghrc.earthdata.nasa.gov/s3credentials',\n",
    "    'nsidc': 'https://data.nsidc.earthdatacloud.nasa.gov/s3credentials'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "121a40a0-2f8b-42ab-8cdf-fe4fe61b9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_temp_creds(provider):\n",
    "    try:\n",
    "        response = requests.get(s3_cred_endpoint[provider])\n",
    "        response.raise_for_status()  # This will raise an error if the HTTP request returned an error status code\n",
    "        return response.json()  # Assuming the response is in JSON format\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to get credentials for {provider}. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "temp_creds_req = get_temp_creds('nsidc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f2bf38f-2856-45c9-b02b-57c6cbf8b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open connection to S3 using credentials\n",
    "\n",
    "if temp_creds_req and 'accessKeyId' in temp_creds_req:\n",
    "    fs_s3 = s3fs.S3FileSystem(anon=False, \n",
    "                              key=temp_creds_req['accessKeyId'], \n",
    "                              secret=temp_creds_req['secretAccessKey'], \n",
    "                              token=temp_creds_req['sessionToken'])\n",
    "else:\n",
    "    print(\"Failed to obtain valid S3 credentials.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae58147f-9657-4292-9463-7d5b32aed350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "cmct_datasets_dir = '/efs/CmCt/datasets/'\n",
    "year = '2003'\n",
    "cmct_files = glob.glob(cmct_datasets_dir + '/GLAS_Data_orig/' + year + '/*.nc')#greenland\n",
    "# print(cmct_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adebc979-ab6d-4cd7-b1c5-0a2836fe1692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/users_conda_envs/cmct_invt/lib/python3.9/site-packages/osgeo/gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import raster\n",
    "\n",
    "\n",
    "gimp_dem_filename = cmct_datasets_dir + \"/GIMP_data/gimpdem_90m_v01.1.tif\"\n",
    "gimp_mask_filename = cmct_datasets_dir + \"/GIMP_data/GimpIceMask_90m_2015_v1.2.tif\"\n",
    "\n",
    "\n",
    "gimp_dem = raster.readRasterBandAsArray(gimp_dem_filename, 1)\n",
    "gimp_dem_gt = raster.getCoordinates(gimp_dem_filename, 1)\n",
    "\n",
    "gimp_mask = raster.readRasterBandAsArray(gimp_mask_filename, 1)\n",
    "gimp_mask_gt = raster.getCoordinates(gimp_mask_filename, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "680fd1a8-ae08-4e6c-a806-b51f6d695a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90.0, 90.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rasterio\n",
    "\n",
    "\n",
    "# Reading the raster file to extract its pixel size\n",
    "with rasterio.open(gimp_dem_filename) as src:\n",
    "    # Pixel width and height (cell size in x and y)\n",
    "    pixel_size_x = src.transform[0]\n",
    "    pixel_size_y = -src.transform[4]  # Negative because pixel sizes are usually stored as negative values\n",
    "\n",
    "pixel_size_x, pixel_size_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e985df1-e967-4fbe-9a04-70a5c1c9b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Evaluate gradient in two dimensions\n",
    "#cellsize_x and cellsize_y are both 90 meters\n",
    "px, py = np.gradient(gimp_dem, 90,90)\n",
    "slope = np.sqrt(px ** 2 + py ** 2)\n",
    "\n",
    "#in degrees, convert using\n",
    "slope_deg = np.degrees(np.arctan(slope))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3be2b8a7-2456-4d31-a453-142da3ebe818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bilinear_interpolate import *\n",
    "\n",
    "def sampleRasterAtPoint(rasterArray, geoTransform, xs, ys, method='bilinear', nodataValue=np.nan):\n",
    "    zs = np.full(xs.shape, np.nan)  # Assuming xs and ys have the same shape\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(xs.flat, ys.flat)):\n",
    "        imagex = (x - geoTransform[0]) / geoTransform[1]\n",
    "        imagey = (y - geoTransform[3]) / geoTransform[5]\n",
    "\n",
    "        if (0 <= imagex < rasterArray.shape[1]) and (0 <= imagey < rasterArray.shape[0]):\n",
    "            if method == 'nearest':\n",
    "                zs.flat[i] = rasterArray[int(np.floor(imagey)), int(np.floor(imagex))]\n",
    "            elif method == 'bilinear':\n",
    "                zs.flat[i] = bilinear_interpolate(rasterArray, imagex, imagey, nodataValue=nodataValue)\n",
    "\n",
    "            if zs.flat[i] == nodataValue:\n",
    "                zs.flat[i] = np.nan\n",
    "\n",
    "    return zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df8ca5b7-13df-4c49-8f79-865eb64a597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sample_gimp_dem_mask(gimp_dem, gimp_mask,slope_deg, gimp_dem_gt, gimp_mask_gt, xs, ys):\n",
    "    \n",
    "    # Check if xs and ys are single numbers (scalars)\n",
    "    if np.isscalar(xs) and np.isscalar(ys):\n",
    "        # Directly sample the raster at the single point\n",
    "        gimp_dem_sampled = sampleRasterAtPoint(gimp_dem, gimp_dem_gt, xs, ys, method='bilinear')\n",
    "        slope_deg_sampled = sampleRasterAtPoint(slope_deg, gimp_dem_gt, xs, ys, method='bilinear')\n",
    "        gimp_mask_sampled = sampleRasterAtPoint(gimp_mask, gimp_mask_gt, xs, ys, method='nearest')\n",
    "        return gimp_dem_sampled, gimp_mask_sampled\n",
    "    \n",
    "    # Otherwise, handle them as arrays\n",
    "    gimp_dem_sampled = np.empty_like(xs, dtype=np.float64)\n",
    "    slope_deg_sampled= np.empty_like(xs, dtype=np.float64)\n",
    "    gimp_mask_sampled = np.empty_like(ys, dtype=np.float64)\n",
    "    \n",
    "    # Use np.ndindex for multidimensional index iteration\n",
    "    for index in np.ndindex(xs.shape):\n",
    "        x = xs[index]\n",
    "        y = ys[index]\n",
    "        gimp_dem_sampled[index] = sampleRasterAtPoint(gimp_dem, gimp_dem_gt, x, y, method='bilinear')\n",
    "        slope_deg_sampled[index] = sampleRasterAtPoint(slope_deg, gimp_dem_gt, x, y, method='bilinear')\n",
    "        gimp_mask_sampled[index] = sampleRasterAtPoint(gimp_mask, gimp_mask_gt, x, y, method='nearest')\n",
    "    \n",
    "    return gimp_dem_sampled, gimp_mask_sampled,slope_deg_sampled\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "303a3824-51ae-4dc1-8c42-4bbc590f6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the drainage system for a given point\n",
    "def find_drainage_system(lat,lon, polygons):\n",
    "    point = Point(lat, lon)\n",
    "    for drainage_id, polygon in polygons.items():\n",
    "        if polygon.contains(point):\n",
    "            return drainage_id\n",
    "    return None  # Or some default value if the point doesn't fall in any polygon\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5f2de-dd1e-4070-bb88-3b1a7defc14d",
   "metadata": {},
   "source": [
    "#### Saving the filtered data to .nc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee372da4-6f5b-40bb-ad8f-db695f0d7351",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "def write_data_to_ncfile(nc_filename, time, lat_filtered, lon_filtered, elev_filtered, WGS84ELEV_M_filtered, EGM08MEANTIDEELEV_M_filtered, EGM08TIDEFREEELEV_M_filtered, ELEV_STDDEV_M_filtered, SLOPE_DEG_filtered, reflectivity_filtered, uncertainty_filtered, reference_elev_filtered, instrument_gain_filtered, gimp_dem_elev, drainage_ids, Icetype_filtered):\n",
    "    with nc.Dataset(nc_filename, 'w', format='NETCDF4') as root_grp:\n",
    "        \n",
    "        \n",
    "        root_grp.createDimension('t', None)  # Unlimited dimension\n",
    "        root_grp.createDimension('phony_dim_1', len(lat_filtered))\n",
    "\n",
    "        # Create variables\n",
    "        dset_time = root_grp.createVariable('TIME', 'f8', ('t',), fill_value=9.96920996838687e+36)\n",
    "        dset_lat = root_grp.createVariable('LAT_DEGN', 'f8', ('t'),fill_value=9.96920996838687e+36)\n",
    "        dset_lon = root_grp.createVariable('LON_DEGE', 'f8', ('t',),fill_value=9.96920996838687e+36)\n",
    "        dset_TOPEXELEV = root_grp.createVariable('TOPEXELEV_M', 'f4', ('t',),fill_value=9.96921e+36)\n",
    "\n",
    "        \n",
    "        ##check it again      \n",
    "        dset_WGS84ELEV = root_grp.createVariable('WGS84ELEV_M', 'f4', ('t',),fill_value=9.96921e+36)\n",
    "        dset_EGM08MEANTIDE = root_grp.createVariable('EGM08MEANTIDEELEV_M','f4', ('t',) ,fill_value=9.96921e+36)\n",
    "        dset_EGM08TIDE = root_grp.createVariable('EGM08TIDEFREEELEV_M','f4', ('t',),fill_value= 9.96921e+36)\n",
    "        dset_ELEV_STDDEV = root_grp.createVariable('ELEV_STDDEV_M','f4', ('t',),fill_value= 9.96921e+36 )\n",
    "        dset_SLOPE_DEG = root_grp.createVariable('SLOPE_DEG','f4', ('t',),fill_value= 9.96921e+36 )\n",
    "             \n",
    "\n",
    "        \n",
    "        dset_REFL_UNCORR = root_grp.createVariable('REFL_UNCORR', 'f4', ('t',),fill_value= 9.96921e+36)\n",
    "        dset_WF_FIT_SIGMA_M = root_grp.createVariable('WF_FIT_SIGMA_M', 'f4', ('t',),fill_value= 9.96921e+36)        \n",
    "        dset_GAIN = root_grp.createVariable('GAIN', 'i4', ('t',),fill_value=-2147483647)     \n",
    "        dset_DEM_M= root_grp.createVariable('DEM_M', 'i4', ('t',),fill_value=-2147483647)\n",
    "        dset_DRAINAGESYSTEM = root_grp.createVariable('DRAINAGESYSTEM','f4', ('t',),fill_value=9.96921e+36 )\n",
    "        dset_ICETYPE = root_grp.createVariable('ICETYPE', 'i4', ('t',),fill_value=-2147483647 )        \n",
    "        \n",
    "              \n",
    "\n",
    "        # Set data\n",
    "        dset_time[:] = time\n",
    "        dset_lat[:] = lat_filtered\n",
    "        dset_lon[:] = lon_filtered\n",
    "        dset_TOPEXELEV[:] = elev_filtered\n",
    "        \n",
    "        dset_WGS84ELEV[:]=WGS84ELEV_M_filtered\n",
    "        dset_EGM08MEANTIDE[:]=EGM08MEANTIDEELEV_M_filtered\n",
    "        dset_EGM08TIDE[:]=EGM08TIDEFREEELEV_M_filtered\n",
    "        dset_ELEV_STDDEV[:]=ELEV_STDDEV_M_filtered\n",
    "        dset_SLOPE_DEG[:]=SLOPE_DEG_filtered\n",
    "        \n",
    "        dset_REFL_UNCORR[:]=reflectivity_filtered\n",
    "        dset_WF_FIT_SIGMA_M[:]=uncertainty_filtered\n",
    "        dset_GAIN[:]=instrument_gain_filtered\n",
    "        dset_DEM_M[:]=gimp_dem_elev\n",
    "        dset_DRAINAGESYSTEM[:]=drainage_ids\n",
    "        dset_ICETYPE[:]=Icetype_filtered\n",
    "        \n",
    "\n",
    "\n",
    "        # Set attributes for TIME\n",
    "        dset_time.setncattr_string('units', \"seconds\")\n",
    "        dset_time.setncattr_string('long_name', \"UTC seconds since 2000-01-01 00:00:00\")\n",
    "        dset_time.setncattr_string('standard_name' ,\"time\")\n",
    "     \n",
    "        \n",
    "        # Set attributes for LAT_DEGN\n",
    "        dset_lat.setncattr_string('units',\"degrees_north\")\n",
    "        dset_lat.setncattr_string('long_name', \"latitude_north\")\n",
    "        dset_lat.setncattr_string('standard_name' , \"latitude\")\n",
    "        dset_lat.valid_min = 59\n",
    "        dset_lat.valid_max = 83.5\n",
    "      \n",
    "\n",
    "        # Set attributes for LON_DEGE\n",
    "        dset_lon.setncattr_string('units',\"degrees_east\")\n",
    "        dset_lon.setncattr_string('long_name', \"longitude_east\")\n",
    "        dset_lon.setncattr_string('standard_name' , \"longitude\")\n",
    "        dset_lon.valid_min = 285\n",
    "        dset_lon.valid_max = 350\n",
    "    \n",
    "        \n",
    "        \n",
    "         # Set attributes \n",
    "        dset_TOPEXELEV.setncattr_string('units', \"meters\")\n",
    "        dset_TOPEXELEV.setncattr_string('long_name', \"Elevation relative to TOPEX/Poseidon ellipsoid\")\n",
    "        dset_TOPEXELEV.setncattr_string('standard_name' , \"height_above_reference_ellipsoid\" )\n",
    "        dset_TOPEXELEV.valid_min = 0 \n",
    "        dset_TOPEXELEV.valid_max= 3500 \n",
    "  \n",
    "        \n",
    "        dset_WGS84ELEV.setncattr_string('units', \"meters\" )\n",
    "        dset_WGS84ELEV.setncattr_string('long_name', \"Elevation relative to WGS84 ellipsoid\") \n",
    "        dset_WGS84ELEV.setncattr_string('standard_name', \"height_above_reference_ellipsoid\") \n",
    "        dset_WGS84ELEV.valid_min = 0 \n",
    "        dset_WGS84ELEV.valid_max = 3500 \n",
    " \n",
    "        \n",
    "        dset_EGM08MEANTIDE.setncattr_string('units', \"meters\" )\n",
    "        dset_EGM08MEANTIDE.setncattr_string('long_name', \"Elevation relative to the EGM08 mean-tide geoid\")\n",
    "        dset_EGM08MEANTIDE.setncattr_string('standard_name' , \"height_above_reference_geoid\" )\n",
    "        dset_EGM08MEANTIDE.valid_min = -150 \n",
    "        dset_EGM08MEANTIDE.valid_max = 3500 \n",
    "     \n",
    "        \n",
    "        dset_EGM08TIDE.setncattr_string('units', \"meters\" )\n",
    "        dset_EGM08TIDE.setncattr_string('long_name',\"Elevation relative to the EGM08 tide-free geoid\")\n",
    "        dset_EGM08TIDE.setncattr_string('standard_name', \"height_above_reference_geoid\")\n",
    "        dset_EGM08TIDE.valid_min = -150 \n",
    "        dset_EGM08TIDE.valid_max = 3500 \n",
    "   \n",
    "        \n",
    "        dset_ELEV_STDDEV.setncattr_string('units', \"meters\")\n",
    "        dset_ELEV_STDDEV.setncattr_string('long_name', \"Uncertainty in elevation based on unpublished analysis by John Dimarzio (john.dimarzio@nasa.gov). Uncertainties are a function of GLAS campaign period and surface slope\" )\n",
    "        dset_ELEV_STDDEV.setncattr_string('nonstandard_name',\"1_standard_deviation_height_uncertainty\" )\n",
    "        dset_ELEV_STDDEV.setncattr_string('coverage_content_type',  \"qualityInformation\" )\n",
    "        dset_ELEV_STDDEV.valid_min = 0.\n",
    "        dset_ELEV_STDDEV.valid_max = 0.5\n",
    "       \n",
    "        \n",
    "        dset_SLOPE_DEG.setncattr_string('units', \"meters\" )\n",
    "        dset_SLOPE_DEG.setncattr_string('long_name', \"surface_slope at nearest node from GLAS elevation grid\")\n",
    "        dset_SLOPE_DEG.setncattr_string('nonstandard_name' , \"slope\" )\n",
    "        dset_SLOPE_DEG.valid_min = 0.\n",
    "        dset_SLOPE_DEG.valid_max = 0.5 \n",
    "  \n",
    "        dset_REFL_UNCORR.setncattr_string('units', \"dimensionless\" )\n",
    "        dset_REFL_UNCORR.setncattr_string('long_name', \"Uncorrected reflectivity from the GLAS data records\" )\n",
    "        dset_REFL_UNCORR.setncattr_string('nonstandard_name' ,\"surface_reflectivity\" )\n",
    "        dset_REFL_UNCORR.valid_min = 0.\n",
    "        dset_REFL_UNCORR.valid_max = 2. \n",
    "\n",
    "        dset_WF_FIT_SIGMA_M.setncattr_string('units',\"volts\")\n",
    "        dset_WF_FIT_SIGMA_M.setncattr_string('long_name',\"Standard deviation of the fit to the waveform from GLAS data record\") \n",
    "        dset_WF_FIT_SIGMA_M.setncattr_string('nonstandard_name' ,  \"uncertainty\") \n",
    "        dset_WF_FIT_SIGMA_M.setncattr_string('coverage_content_type', \"qualityInformation\")       \n",
    "        dset_WF_FIT_SIGMA_M.valid_min = 0. \n",
    "        dset_WF_FIT_SIGMA_M.valid_max = 2.\n",
    "   \n",
    "\n",
    "        dset_GAIN.setncattr_string('units', \"dimensionless \")\n",
    "        dset_GAIN.setncattr_string('long_name', \"Instrument gain from the GLAS data record\")\n",
    "        dset_GAIN.setncattr_string('nonstandard_name' ,  \"instrument_gain\")\n",
    "        dset_GAIN.setncattr_string('coverage_content_type', \"qualityInformation\")\n",
    "        dset_GAIN.valid_min = 1 \n",
    "        dset_GAIN.valid_max = 250\n",
    "   \n",
    "\n",
    "        dset_DEM_M.setncattr_string('units', \"meters\") \n",
    "        dset_DEM_M.setncattr_string('long_name',\"height relative to WGS84 at nearest node of the reference DEM\")\n",
    "        dset_DEM_M.setncattr_string('standard_name', \"height_above_reference_ellipsoid\") \n",
    "        dset_DEM_M.setncattr_string('coverage_content_type',  \"qualityInformation\")\n",
    "        dset_DEM_M.valid_min = 0\n",
    "        dset_DEM_M.valid_max = 3500\n",
    "\n",
    "\n",
    "        \n",
    "        dset_DRAINAGESYSTEM.setncattr_string('units', \"dimensionless \")\n",
    "        dset_DRAINAGESYSTEM.setncattr_string('long_name',\"Drainage system or subsystem based on Mario Giovinetto\\'s analysis of ICESat/GLAS data\")\n",
    "        dset_DRAINAGESYSTEM.setncattr_string('nonstandard_name' , \"drainage_system_id\")\n",
    "        dset_DRAINAGESYSTEM.setncattr_string('reference_url', \"http://icesat4.gsfc.nasa.gov/cryo_data/ant_grn_drainage_systems.php\") \n",
    "        dset_DRAINAGESYSTEM.valid_min= 0\n",
    "        dset_DRAINAGESYSTEM.valid_max = 27\n",
    "\n",
    "        \n",
    "        \n",
    "        dset_ICETYPE.setncattr_string('units', \"dimensionless \")\n",
    "        dset_ICETYPE.setncattr_string('long_name', \"Ice type \")\n",
    "        dset_ICETYPE.setncattr_string('comment_1', \"0: isolated ice cap (Greenland only). \")\n",
    "        dset_ICETYPE.setncattr_string('comment_2', \"1: coterminous ice sheet. \")\n",
    "        dset_ICETYPE.setncattr_string('comment_3', \"2: ice shelf (Antarctica only). \")\n",
    "        dset_ICETYPE.setncattr_string('nonstandard_name', \"icetype_flag \")\n",
    "        dset_ICETYPE.setncattr_string('reference_url', \"http://nsidc.org/data/docs/agdc/nsidc0489_bindschadler/ \")\n",
    "        dset_ICETYPE.setncattr_string('reference', \"The Cryosphere, 5, 569–588, 2011. doi:10.5194/tc-5-569-2011\")                          \n",
    "        dset_ICETYPE.valid_min = 0\n",
    "        dset_ICETYPE.valid_max = 2        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        # Set global attributes\n",
    "        root_grp.setncattr_string('id',\"GLA12_634_2131_002_0057_0_01_0001.CMCT.final.nc\")\n",
    "        root_grp.setncattr_string('date_created', \"2016-Jun-22 UTC\")\n",
    "        root_grp.setncattr_string('product_version',\"R634\")\n",
    "        root_grp.setncattr_string('history', \"GLA12_634_2131_002_0057_0_01_0001.CMCT.final.nc created Wed Jun 22 19:44:41 2016 by Saba using make_glas_cmct_netcdf.pro, IDL 8.4 run on gs6141-atlas. Input file: /data1/jack/CMCT/GLAS_Data/R634_Greenland/L2F/GLA12_634_2131_002_0057_0_01_0001.CMCT.final.dat\")\n",
    "        root_grp.setncattr_string('keywords', \"altimetry, glaciology, modeling, Greenland\")\n",
    "        root_grp.setncattr_string('geographic_identifier', \"Greenland\")\n",
    "        \n",
    "        \n",
    "        root_grp.setncattr('geospatial_lat_min', np.int32(59))\n",
    "        root_grp.setncattr('geospatial_lat_max', np.float32(83.5))\n",
    "        root_grp.setncattr('geospatial_lon_min', np.int32(285))\n",
    "        root_grp.setncattr('geospatial_lon_max', np.int32(350))\n",
    "        root_grp.setncattr('geospatial_vertical_max', np.int32(3500))\n",
    "\n",
    "        \n",
    "        root_grp.setncattr_string('creator_name', \"Jack Saba\")\n",
    "        root_grp.setncattr_string('creator_email', \"jack.saba@nasa.gov\")\n",
    "        root_grp.setncattr_string('institution', \"NASA/GSFC Code 615\")\n",
    "        root_grp.setncattr_string('project', \"Cryospheric Model Comparison Tool\")\n",
    "        root_grp.setncattr_string('publisher_name_1', \"Thomas Neumann\" )\n",
    "        root_grp.setncattr_string('publisher_name_2', \"Sophie Nowicki\" )                         \n",
    "        root_grp.setncattr_string('publisher_email_1', \"Thomas.Neumann@nasa.gov\")\n",
    "        root_grp.setncattr_string('publisher_email_2',\"sophie.nowicki@nasa.gov\" )\n",
    "        root_grp.setncattr_string('geospatial_lat_units', \"degrees_north\")                        \n",
    "        root_grp.setncattr_string('geospatial_lon_units', \"degrees_east\")\n",
    "        root_grp.setncattr_string('geospatial_vertical_units_1', \"height above the TOPEX/Poseidon ellipsoid, in meters\")\n",
    "        root_grp.setncattr_string('geospatial_vertical_units_2', \"EPSG:4979 (height above the WGS84 ellipsoid, in meters)\" )\n",
    "        root_grp.setncattr_string('geospatial_vertical_units_3', \"height above the EGM08 mean-tide geoid, in meters\")\n",
    "        root_grp.setncattr_string('geospatial_vertical_units_4', \"height above the EGM08 tide-free geoid, in meters\")\n",
    "        root_grp.setncattr_string('geospatial_vertical_min_1', \"0\" )                         \n",
    "        root_grp.setncattr_string('geospatial_vertical_min_2', \"0\" )  \n",
    "        root_grp.setncattr_string('geospatial_vertical_min_3', \"0\" )                         \n",
    "        root_grp.setncattr_string('geospatial_vertical_min_4', \"0\")\n",
    "        root_grp.setncattr_string('geospatial_bounds_crs', \"EPSG:4979 (WGS84)\" )                        \n",
    "        root_grp.setncattr_string('naming_authority', \"nasa/gsfc/code_615\" ) \n",
    "                           \n",
    "        root_grp.setncattr_string('references_1',\"Bamber, Jonathan L., Jose Luis Gomez-Dans, and Jennifer A. Griggs. 2009. Antarctic 1 km Digital Elevation Model (DEM) from Combined ERS-1 Radar and ICESat Laser Satellite Altimetry. Boulder, Colorado USA: National Snow and Ice Data Center. Digital media. https://nsidc.org/data/docs/daac/nsidc0422_antarctic_1km_dem/\")\n",
    "        root_grp.setncattr_string('references_2' , \"Bamber, J. L., J. L. Gomez-Dans, and J. A. Griggs. 2009. A New 1 km Digital Elevation Model of the Antarctic Derived from Combined Satellite Radar and Laser Data Part 1: Data and Methods. The Cryosphere, 3, 101-111\")\n",
    "        root_grp.setncattr_string('references_3',\"Bindschadler, R., H. Choi, A. Wichlac2, R. Bingham, J. Bohlander, K. Brunt, H. Corr, R. Drews, H. Fricker, M. Hall, R. Hindmarsh, J. Kohler, L. Padman, W. Rack, G. Rotschky, S. Urbini, P. Vornberger, and N. Young, 2011, Getting around Antarctica: new high-resolution mappings of the grounded and freely-floating boundaries of the Antarctic ice sheet created for the International Polar Year, The Cryosphere, 5, 569–588, doi:10.5194/tc-5-569-2011a\" )\n",
    "        root_grp.setncattr_string('references_4' ,  \"Bindschadler, R., H. Choi, and ASAID Collaborators. 2011b. High-resolution Image-derived Grounding and Hydrostatic Lines for the Antarctic Ice Sheet. Boulder, Colorado, USA: National Snow and Ice Data Center. http://dx.doi.org/10.7265/N56T0JK2\" )\n",
    "        root_grp.setncattr_string('references_5' ,  \"Griggs, J. A. and J. L. Bamber. 2009. A New 1 km Digital Elevation Model of Antarctica Derived from Combined Radar and Laser Data Part 2: Validation and Error Estimates. The Cryosphere, 3, 113123\" )\n",
    "        root_grp.setncattr_string('references_6' , \"Howat, I. M., A. Negrete, and B. E. Smith, 2014, The Greenland Ice Mapping Project (GIMP) land classification and surface elevation data sets, The Cryosphere, 8, 1509–1518, doi:10.5194/tc-8-1509-2014. See https/::bpcrc.osu.edu:gdg:data\" )\n",
    "        root_grp.setncattr_string('references_7' ,  \"Howat, I., A. Negrete, and B. Smith. 2015. MEaSURES Greenland Ice Mapping Project (GIMP) Digital Elevation Model, Version 1. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. http://dx.doi.org/10.5067/NV34YUIXLP9W\" )\n",
    "        root_grp.setncattr_string('references_8' ,  \"Pavlis, Nikolaos K, Simon A. Holmes, Steve C. Kenyon, and John K. Factor , The development and evaluation of the Earth Gravitational Model 2008 (EGM2008), 2012, JGR 117, B04406, doi:10.1029/2011JB008916. http://earth-info.nga.mil/GandG/wgs84/gravitymod/egm2008/\" )\n",
    "        root_grp.setncattr_string('references_9' , \"Shepherd, Andrew, Erik R. Ivins, Geruo A, Valentina R. Barletta, Mike J. Bentley, Srinivas Bettadpur, Kate H. Briggs, David H. Bromwich, René Forsberg, Natalia Galin, Martin Horwath, Stan Jacobs, Ian Joughin, Matt A. King, Jan T. M. Lenaerts, Jilu Li, Stefan R. M. Ligtenberg, Adrian Luckman, Scott B. Luthcke, Malcolm McMillan, Rakia Meister, Glenn Milne, Jeremie Mouginot, Alan Muir, Julien P. Nicolas, John Paden, Antony J. Payne, Hamish Pritchard, Eric Rignot, Helmut Rott, Louise Sandberg Sørensen, Ted A. Scambos, Bernd Scheuchl, Ernst J. O. Schrama, Ben Smith, Aud V. Sundal, Jan H. van Angelen, Willem J. van de Berg, Michiel R. van den Broeke, David G. Vaughan, Isabella Velicogna, John Wahr, Pippa L. Whitehouse, Duncan J. Wingham, Donghui Yi, Duncan Young, and H. Jay Zwally, 2012, A Reconciled Estimate of Ice-Sheet Mass Balance, Science 338, 1183 (2012). doi:10.1126/science.1228102\")\n",
    "\n",
    "        root_grp.setncattr_string('processing_level' , \"final\") \n",
    "        root_grp.setncattr_string('comments', \"The drainage systems (DS) were determined from grids based on the DS boundaries generated by Mario Giovinetto (http://icesat4.gsfc.nasa.gov/cryo_data/ant_grn_drainage_systems.php) were used to generate 500m (for Antarctica) and 1 km (for Greenland) DS ids the DS was assigned based on the DS of the nearest node. The DS grids were generated by John Robbins.\" )\n",
    "        root_grp.setncattr_string('acknowledgement', \"We acknowledge support from the NASA Cryospheric Sciences Program\") \n",
    "        root_grp.setncattr_string('license', \"Freely Distributed\" )\n",
    "        root_grp.setncattr_string('program',\"Cryospheric Model Comparison Tool (CMCT)\" )\n",
    "\n",
    "\n",
    "        print(f\"Data saved to {nc_filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "345ac501-5af6-4643-a3cb-2704b568572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from collections import defaultdict\n",
    "\n",
    "# Assuming 'data' is your data from GrnDrainageSystems_Ekholm_epsg3413.txt\n",
    "data = pd.read_csv('/efs/data/Ice_Sheet_Drainage_Systems/GrnDrainageSystems_Ekholm_epsg3413.txt', sep='\\t', header=None, names=['x', 'y', 'drainage_id'])\n",
    "\n",
    "# Group points by drainage system ID\n",
    "grouped = data.groupby('drainage_id')\n",
    "\n",
    "# Create polygons for each drainage system\n",
    "polygons = {drainage_id: Polygon(points.values) for drainage_id, points in grouped[['x', 'y']]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3e7080d-bdb1-4bb3-95d4-82681a1b2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import netCDF4 as nc\n",
    "outputdir='/efs/CmCt/datasets/GLAS_Data/'+year+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e15f9da4-d7d2-413f-a159-2aa1c87e640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://nsidc-cumulus-prod-protected/GLAS/GLAH12/034/2003/11/GLAH12_634_2103_002_0337_0_01_0001.H5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/efs/CmCt/datasets/GLAS_Data/2003/GLAH12_634_2103_002_0337_0_01_0001.CMCT.final.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import progressbar\n",
    "from pyproj import Transformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "all_data = []  # List to store individual DataFrames for each cmct file\n",
    "bar = progressbar.ProgressBar()\n",
    "for cmct_file in bar(cmct_files):\n",
    "\n",
    "    #Greenland\n",
    "    cmct_file_basename = cmct_file.split('/')[-1].split('.')[0].replace('GLA12','GLAH12')\n",
    "        \n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3413\")#Greenland\n",
    "    \n",
    "    for data_link in data_links:\n",
    "        try:\n",
    "            if cmct_file_basename in data_link[0]:\n",
    "                print(data_link[0])\n",
    "\n",
    "                #read glah data\n",
    "                f_glah = h5py.File(fs_s3.open(data_link[0], 'rb'))\n",
    "\n",
    "                # Extract relevant datasets\n",
    "\n",
    "                #time\n",
    "                time_glah = f_glah['Data_40HZ']['Time']['d_UTCTime_40'][:]\n",
    "\n",
    "                #a. Latitude \n",
    "                LAT_glah = f_glah['Data_40HZ']['Geolocation']['d_lat'][:]\n",
    "\n",
    "                # b.Longitude\n",
    "                LON_glah = f_glah['Data_40HZ']['Geolocation']['d_lon'][:]\n",
    "\n",
    "                #c.Elevation \n",
    "                elev_glah = f_glah['Data_40HZ']['Elevation_Surfaces']['d_elev'][:]\n",
    "             \n",
    "                WGS84ELEV_M_glah = f_glah['Data_40HZ']['Elevation_Surfaces']['d_elev'][:] - f_glah['Data_40HZ']['Geophysical']['d_deltaEllip'][:]\n",
    "\n",
    "                ## assining value(NaN/0.5) for these unknown variables\n",
    "                size_of_array = elev_glah.shape\n",
    "                # Creating arrays with the same size              \n",
    "                EGM08MEANTIDEELEV_M_glah = np.full(size_of_array, np.nan)  # Filled with NaN\n",
    "                EGM08TIDEFREEELEV_M_glah = np.full(size_of_array, np.nan)  # Filled with NaN            \n",
    "                ELEV_STDDEV_M_glah = np.full(size_of_array, 0.5)           # Filled with 0.5\n",
    "\n",
    "\n",
    "                #d. Reflectivity \n",
    "                reflectivity_glah = f_glah['Data_40HZ']['Reflectivity']['d_reflctUC'][:]\n",
    "\n",
    "                #e. GLAS fitting uncertainty \n",
    "                uncertainty_glah = f_glah['Data_40HZ']['Elevation_Surfaces']['d_IceSVar'][:]\n",
    "\n",
    "\n",
    "                #f. The reference elevation that was stored in the GLAS data records       \n",
    "                reference_elev_glah = f_glah['Data_40HZ']['Geophysical']['d_DEM_elv'][:]\n",
    "\n",
    "                #h.The instrument gain \n",
    "                instrument_gain_glah = f_glah['Data_40HZ']['Waveform']['i_gval_rcv'][:]\n",
    "\n",
    "\n",
    "\n",
    "                #1. Project GLAS latitude/longitude into EPSG:3413 polar stereographic projection\n",
    "                x, y = transformer.transform(LAT_glah, LON_glah)\n",
    "\n",
    "\n",
    "                # Sample the GIMP ice mask and GIMP DEM elevation and slope for the projected coordinates\n",
    "                gimp_dem_sampled, gimp_mask_sampled,slope_deg_sampled=sample_gimp_dem_mask(gimp_dem,gimp_mask,slope_deg,gimp_dem_gt,gimp_mask_gt, x, y)\n",
    "\n",
    "\n",
    "                # 2. Filter out points not on ice\n",
    "                on_ice_mask = (gimp_mask_sampled >= 1) & (gimp_mask_sampled <= 3)#if values are 1,2and 3\n",
    "\n",
    "                #A flag indicating whether the data are on the ice sheet or an ice shelf\n",
    "                # Icetype: 1 for ice shelf (gimp_mask_sampled = 3), 0 for ice sheet (gimp_mask_sampled = 1 or 2or 0)\n",
    "                Icetype = np.where(gimp_mask_sampled == 3, 1, 0)                \n",
    "\n",
    "                # 3. Filter out points with elevation difference <= 200          \n",
    "                elev_diff_mask = np.abs(elev_glah - gimp_dem_sampled) <= 200\n",
    "\n",
    "                # 4. Filter points based on GLAS surface reflectivity           \n",
    "                reflectivity_mask = reflectivity_glah >= 0.0375\n",
    "\n",
    "                # 5. Filter points based on GLAS elevation uncertaint\n",
    "                uncertainty_mask = uncertainty_glah <= 0.0375\n",
    "\n",
    "                \n",
    "\n",
    "                # Combine all filters\n",
    "                combined_mask = on_ice_mask & elev_diff_mask & reflectivity_mask & uncertainty_mask\n",
    "\n",
    "\n",
    "                #6. Filter the data based on the combined mask\n",
    "                time_filtered=time_glah[combined_mask]\n",
    "                lat_filtered = LAT_glah[combined_mask]\n",
    "                lon_filtered = LON_glah[combined_mask]\n",
    "                elev_filtered = elev_glah[combined_mask]\n",
    "                WGS84ELEV_M_filtered = WGS84ELEV_M_glah[combined_mask]\n",
    "\n",
    "                EGM08MEANTIDEELEV_M_filtered = EGM08MEANTIDEELEV_M_glah[combined_mask] \n",
    "                EGM08TIDEFREEELEV_M_filtered = EGM08TIDEFREEELEV_M_glah[combined_mask]\n",
    "                ELEV_STDDEV_M_filtered = ELEV_STDDEV_M_glah[combined_mask]\n",
    "                \n",
    "                SLOPE_DEG_filtered= slope_deg_sampled[combined_mask]\n",
    "                reflectivity_filtered=reflectivity_glah[combined_mask]\n",
    "                uncertainty_filtered=uncertainty_glah[combined_mask]\n",
    "                reference_elev_filtered=reference_elev_glah[combined_mask]\n",
    "                instrument_gain_filtered =instrument_gain_glah[combined_mask]\n",
    "\n",
    "\n",
    "                #g.The elevation from the GIMP or Bamber DEM.            \n",
    "                gimp_dem_elev=gimp_dem_sampled[combined_mask]\n",
    "\n",
    "                #i.The drainage system ID            \n",
    "                x_filtered=x[combined_mask]\n",
    "                y_filtered=y[combined_mask]\n",
    "                drainage_ids = [find_drainage_system(lat1, lon1, polygons) for lat1, lon1 in zip(x_filtered, y_filtered)]\n",
    "\n",
    "\n",
    "                #j.A flag indicating whether the data are on the ice sheet or an ice shelf\n",
    "                # Icetype: 1 for ice shelf (gimp_mask_sampled = 3), 0 for ice sheet (gimp_mask_sampled = 1 or 2)\n",
    "                Icetype_filtered = Icetype[combined_mask]\n",
    "\n",
    "                # Replace None with a specific numerical value, e.g., -1\n",
    "                none_value = -1\n",
    "                drainage_ids_with_value = [none_value if x is None else x for x in drainage_ids]\n",
    "                # Name of output file\n",
    "                # Split the string at each '/'\n",
    "                parts = data_link[0].split('/')\n",
    "\n",
    "                # The file name is the last element in the list\n",
    "                file_name = parts[-1]\n",
    "\n",
    "                # CmCt file name\n",
    "                nc_fname = file_name.rsplit('.', 1)[0] + '.CMCT.final.nc'\n",
    "                # print(nc_fname)\n",
    "\n",
    "                # Create a new NetCDF file\n",
    "                fname = f'{outputdir}'+ nc_fname## filename\n",
    "                print(fname)\n",
    "\n",
    "\n",
    "                # save the output data to .nc file\n",
    "                write_data_to_ncfile(fname,time_filtered,lat_filtered,lon_filtered,elev_filtered,WGS84ELEV_M_filtered,EGM08MEANTIDEELEV_M_filtered,EGM08TIDEFREEELEV_M_filtered,ELEV_STDDEV_M_filtered,SLOPE_DEG_filtered,reflectivity_filtered,uncertainty_filtered,reference_elev_filtered,instrument_gain_filtered,gimp_dem_elev,drainage_ids_with_value,Icetype_filtered)\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError encountered in file {data_link[0]}: {e}\")\n",
    "            continue  # Skip the rest of the loop and move to the next file\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787add23-9724-4fa5-a776-f6bfeeafdcba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cmct_invt]",
   "language": "python",
   "name": "conda-env-cmct_invt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
